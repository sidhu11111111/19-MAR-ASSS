{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ea6218",
   "metadata": {},
   "source": [
    "# QNO.1 ANS\n",
    " Min-Max scaling, also known as normalization, is a data preprocessing technique used to rescale numeric features to a specific range, typically between 0 and 1. It works by subtracting the minimum value from each data point and then dividing it by the range (the difference between the maximum and minimum values). The formula for Min-Max scaling is:\n",
    "\n",
    "Scaled value = (value - min) / (max - min)\n",
    "\n",
    "For example, let's consider a dataset of house prices ranging from $100,000 to $1,000,000. By applying Min-Max scaling, the lowest price ($100,000) would be transformed to 0, the highest price ($1,000,000) would be transformed to 1, and all other prices would be scaled proportionally between 0 and 1 based on their relative positions in the range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f049a43",
   "metadata": {},
   "source": [
    "# QNO.2 ANS\n",
    "The Unit Vector technique, also known as normalization or vector normalization, is a feature scaling method that rescales each sample (row) in a dataset to have a unit norm, i.e., a length of 1. It scales the values of each feature vector so that the Euclidean norm (or other specified norm) of the vector becomes 1. The formula for Unit Vector scaling is:\n",
    "\n",
    "Scaled value = value / norm\n",
    "\n",
    "The norm can be calculated using various methods, such as the L1 norm (sum of absolute values) or the L2 norm (square root of the sum of squared values).\n",
    "\n",
    "The key difference between Unit Vector scaling and Min-Max scaling is that Unit Vector scaling focuses on scaling the vectors to have the same length, while Min-Max scaling adjusts the values within a specific range.\n",
    "\n",
    "For example, suppose we have a dataset of user ratings for different movies, and each user's ratings are represented as a feature vector. By applying Unit Vector scaling, we ensure that each user's rating vector has a length of 1, irrespective of the specific rating values. This normalization allows us to compare and analyze the relative magnitudes and directions of the rating vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b2954",
   "metadata": {},
   "source": [
    "# QNO.3 ANS\n",
    " Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform a high-dimensional dataset into a lower-dimensional space while retaining the most important information. It achieves this by identifying the principal components, which are linear combinations of the original features, capturing the maximum variance in the data. PCA helps in simplifying the dataset and removing redundant or correlated features.\n",
    "    EXAMPLE ARE:\n",
    "        Suppose we have a dataset with five features: height, weight, age, income, and education level. By applying PCA to this dataset, we can derive a new set of uncorrelated variables called principal components. Let's say PCA finds that the first two principal components capture the majority of the variance in the data. We can then represent the dataset using only these two principal components, effectively reducing the dimensionality from five to two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd134192",
   "metadata": {},
   "source": [
    "# QNO.4 ANS\n",
    "PCA can be used for feature extraction by transforming the original features into a new set of features called principal components. These principal components are linear combinations of the original features and are ordered by the amount of variance they capture in the data. Feature extraction with PCA allows us to reduce the dimensionality of the dataset while retaining as much information as possible.\n",
    "\n",
    "For example, let's consider a dataset with ten features. By applying PCA to this dataset, we can obtain a reduced set of principal components, such as the first three components that capture the most variance. These principal components can be treated as new features that represent the original data in a lower-dimensional space. We can then use these principal components as input features for further analysis or modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089155e",
   "metadata": {},
   "source": [
    "# QNO.5 ANS\n",
    "In the project to build a recommendation system for a food delivery service, Min-Max scaling can be used to preprocess the data. Here's how you can apply Min-Max scaling to the features of price, rating, and delivery time:\n",
    "\n",
    "Identify the minimum and maximum values for each feature (price, rating, delivery time) in the dataset.\n",
    "\n",
    "Apply the Min-Max scaling formula to each value in the respective feature column:\n",
    "Scaled value = (value - min) / (max - min)\n",
    "\n",
    "Repeat step 2 for all values in each feature column.\n",
    "\n",
    "The scaled values will now range between 0 and 1. These scaled values can be used as input for the recommendation system.\n",
    "\n",
    "Min-Max scaling ensures that the features are on a similar scale, preventing any particular feature from dominating the others during the recommendation process. It allows for fair comparison and unbiased consideration of different features in the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e3a69",
   "metadata": {},
   "source": [
    "# QNO.6 ANS\n",
    "When building a model to predict stock prices with a dataset containing many features such as company financial data and market trends, PCA can be used to reduce the dimensionality of the dataset. Here's an overview of the steps:\n",
    "\n",
    "Standardize the dataset: Since PCA is based on variance, it is important to standardize the features to have zero mean and unit variance. This ensures that all features contribute equally to the analysis.\n",
    "\n",
    "Perform PCA: Apply PCA to the standardized dataset. The PCA algorithm will identify the principal components, which are linear combinations of the original features that capture the most variance in the data.\n",
    "\n",
    "Determine the number of principal components: Analyze the explained variance ratio or scree plot to understand the amount of variance explained by each principal component. Choose the number of principal components that capture a significant amount of variance, typically aiming to retain a certain percentage (e.g., 95%) of the total variance.\n",
    "\n",
    "Retain principal components: Select the determined number of principal components based on the explained variance and discard the rest. These retained principal components will represent the reduced dimensional representation of the original dataset.\n",
    "\n",
    "By reducing the dimensionality using PCA, you can address the curse of dimensionality, improve computational efficiency, and potentially identify the most informative features for predicting stoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e4bd7",
   "metadata": {},
   "source": [
    "# QNO.7 ANS\n",
    "To perform Min-Max scaling on the dataset [1, 5, 10, 15, 20] and transform the values to a range of -1 to 1, you can follow these steps:\n",
    "\n",
    "Identify the minimum and maximum values in the dataset. In this case, the minimum value is 1, and the maximum value is 20.\n",
    "\n",
    "Apply the Min-Max scaling formula to each value:\n",
    "Scaled value = (value - min) / (max - min)\n",
    "\n",
    "For each value:\n",
    "\n",
    "Scaled value of 1 = (1 - 1) / (20 - 1) = 0\n",
    "Scaled value of 5 = (5 - 1) / (20 - 1) ≈ 0.222\n",
    "Scaled value of 10 = (10 - 1) / (20 - 1) ≈ 0.444\n",
    "Scaled value of 15 = (15 - 1) / (20 - 1) ≈ 0.667\n",
    "Scaled value of 20 = (20 - 1) / (20 - 1) = 1\n",
    "The scaled values now range between 0 and 1. To transform the values to a range of -1 to 1, you can multiply each scaled value by 2 and subtract 1:\n",
    "\n",
    "Scaled value of 1 becomes -1\n",
    "Scaled value of 5 becomes -0.556\n",
    "Scaled value of 10 becomes -0.112\n",
    "Scaled value of 15 becomes 0.334\n",
    "Scaled value of 20 becomes 1\n",
    "Therefore, the Min-Max scaled values of the dataset [1, 5, 10, 15, 20] in the range of -1 to 1 are [-1, -0.556, -0.112, 0.334, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ded3b",
   "metadata": {},
   "source": [
    "# QNO.8 ANS\n",
    "To perform feature extraction using PCA on the dataset containing the features [height, weight, age, gender, blood pressure], the choice of how many principal components to retain depends on the desired trade-off between dimensionality reduction and information retention. Here are some steps to consider:\n",
    "\n",
    "Standardize the dataset: Before applying PCA, it is generally recommended to standardize the features to have zero mean and unit variance. This ensures that all features contribute equally to the analysis.\n",
    "\n",
    "Perform PCA: Apply PCA to the standardized dataset. PCA will identify the principal components, which are linear combinations of the original features that capture the most variance in the data.\n",
    "\n",
    "Analyze the explained variance ratio: Examine the explained variance ratio for each principal component. It represents the proportion of variance explained by each component. Plotting the cumulative explained variance ratio can help determine how many components are needed to retain a certain percentage of the total variance.\n",
    "\n",
    "Determine the number of principal components to retain: Choose the number of principal components based on the desired amount of variance retention. This can be determined by considering the trade-off between dimensionality reduction and the retained information. A common approach is to choose the number of components that capture a significant percentage of the total variance, such as 90% or 95%.\n",
    "\n",
    "Retain principal components: Select the determined number of principal components based on the explained variance ratio analysis. These retained principal components will represent a reduced dimensional representation of the original dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e48fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
